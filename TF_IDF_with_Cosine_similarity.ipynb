{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/Fa05ZqP3Hhqe4JbJjCYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TABEYWICKRAMA/IRWA/blob/main/TF_IDF_with_Cosine_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 04 part 2 - IRWA"
      ],
      "metadata": {
        "id": "8ApFYmmlcL60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF with Cosine Similarity"
      ],
      "metadata": {
        "id": "3TVQgEsncZtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Term Frequency also known as TF measures the number of times a term(word) occurs in a document. Given below is the code and the items and their frequency on each of the document."
      ],
      "metadata": {
        "id": "XhphrjzcclJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z4Onss-TbegC"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#documents\n",
        "doc1 = \"I want to start learning to charge something in life\"\n",
        "doc2 = \"reading something about no one else knows\"\n",
        "doc3 = \"Never stop learning\"\n",
        "\n",
        "#query string\n",
        "query = \"life learning\""
      ],
      "metadata": {
        "id": "5kEY_0AtdBTz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#term-frequency :word occurences in a document\n",
        "#this will show term-frequency for each and every document\n",
        "\n",
        "def compute_tf(docs_list):\n",
        "  for doc in docs_list:\n",
        "    doc1_lst = doc.split(\" \")\n",
        "    wordDict_1 = dict.fromkeys(set(doc1_lst),0)\n",
        "\n",
        "    for token in doc1_lst:\n",
        "      wordDict_1[token] += 1\n",
        "    df = pd.DataFrame([wordDict_1])\n",
        "    idx = 0 \n",
        "    new_col = [\"Term Frequency\"]\n",
        "    df.insert(loc=idx, column='Document', value =new_col)\n",
        "    print(df)\n",
        "compute_tf([doc1,doc2,doc3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJpkkCGFeb9_",
        "outputId": "e093bd85-9c4c-4874-f59f-69f7d3afd894"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Document  to  life  start  I  want  charge  something  learning  in\n",
            "0  Term Frequency   2     1      1  1     1       1          1         1   1\n",
            "         Document  reading  else  knows  no  one  something  about\n",
            "0  Term Frequency        1     1      1   1    1          1      1\n",
            "         Document  Never  learning  stop\n",
            "0  Term Frequency      1         1     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate score for document frequency\n",
        "def termFrequency(term, document):\n",
        "  normalizeDocument = document.lower().split()\n",
        "  return normalizeDocument.count(term.lower())/float(len(normalizeDocument))\n",
        "\n",
        "def compute_normalizedtf(documents):\n",
        "  tf_doc = []\n",
        "  for txt in documents:\n",
        "    sentence = txt.split()\n",
        "    norm_tf = dict.fromkeys(set(sentence),0)\n",
        "    for word in sentence:\n",
        "      norm_tf[word] = termFrequency(word, txt)\n",
        "    tf_doc.append(norm_tf)\n",
        "    df=pd.DataFrame([norm_tf])\n",
        "    idx=0\n",
        "    # define a column as normalized TF\n",
        "    new_col = [\"normalized TF\"]    \n",
        "    df.insert(loc=idx, column='Document',value=new_col)\n",
        "    print(df)\n",
        "  return tf_doc\n",
        "\n",
        "tf_doc = compute_normalizedtf([doc1, doc2, doc3])\n",
        "tf_doc\n",
        "\n",
        "#calculate normalized term frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9RsQMfAix1f",
        "outputId": "0e31da06-11dd-4f65-a9f3-f728796b7b33"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Document   to  life  start    I  want  charge  something  learning  \\\n",
            "0  normalized TF  0.2   0.1    0.1  0.1   0.1     0.1        0.1       0.1   \n",
            "\n",
            "    in  \n",
            "0  0.1  \n",
            "        Document   reading      else     knows        no       one  something  \\\n",
            "0  normalized TF  0.142857  0.142857  0.142857  0.142857  0.142857   0.142857   \n",
            "\n",
            "      about  \n",
            "0  0.142857  \n",
            "        Document     Never  learning      stop\n",
            "0  normalized TF  0.333333  0.333333  0.333333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'to': 0.2,\n",
              "  'life': 0.1,\n",
              "  'start': 0.1,\n",
              "  'I': 0.1,\n",
              "  'want': 0.1,\n",
              "  'charge': 0.1,\n",
              "  'something': 0.1,\n",
              "  'learning': 0.1,\n",
              "  'in': 0.1},\n",
              " {'reading': 0.14285714285714285,\n",
              "  'else': 0.14285714285714285,\n",
              "  'knows': 0.14285714285714285,\n",
              "  'no': 0.14285714285714285,\n",
              "  'one': 0.14285714285714285,\n",
              "  'something': 0.14285714285714285,\n",
              "  'about': 0.14285714285714285},\n",
              " {'Never': 0.3333333333333333,\n",
              "  'learning': 0.3333333333333333,\n",
              "  'stop': 0.3333333333333333}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverse Document Frequency(IDF)"
      ],
      "metadata": {
        "id": "uwdxyDmetD4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inverseDocumentFrequency(term, allDocuments):\n",
        "  numDocumentsWithThisTerm = 0\n",
        "  for doc in range(0,len(allDocuments)):\n",
        "    if term.lower() in allDocuments[doc].lower().split():\n",
        "      numDocumentsWithThisTerm = numDocumentsWithThisTerm + 1\n",
        "\n",
        "  if numDocumentsWithThisTerm >0:\n",
        "    return 1.0 + math.log(float(len(allDocuments))/numDocumentsWithThisTerm)\n",
        "  else:\n",
        "    return 1.0\n",
        "\n",
        "def compute_idf(documents):\n",
        "  idf_dict = {}\n",
        "  for doc in documents:\n",
        "    sentence = doc.split()\n",
        "    for word in sentence:\n",
        "      idf_dict[word] = inverseDocumentFrequency(word, documents)\n",
        "    return idf_dict\n",
        "\n",
        "idf_dict = compute_idf([doc1, doc2, doc3])\n",
        "compute_idf([doc1, doc2, doc3])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAK_Xpk9tKFt",
        "outputId": "acdff619-8556-4c69-eeee-e6ee4bd5b7b9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': 2.09861228866811,\n",
              " 'want': 2.09861228866811,\n",
              " 'to': 2.09861228866811,\n",
              " 'start': 2.09861228866811,\n",
              " 'learning': 1.4054651081081644,\n",
              " 'charge': 2.09861228866811,\n",
              " 'something': 1.4054651081081644,\n",
              " 'in': 2.09861228866811,\n",
              " 'life': 2.09861228866811}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF** - **IDF** "
      ],
      "metadata": {
        "id": "YdhjH3suz47A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf-idf score across all docs for the query string(\"life learning\")\n",
        "def compute_tfidf_with_alldocs(documents, query):\n",
        "  tf_idf = []\n",
        "  index = 0\n",
        "  query_tokens = query.split()\n",
        "  df = pd.DataFrame(columns = ['doc'] + query_tokens)\n",
        "  for doc in documents:\n",
        "    df['doc'] = np.arange(0, len(documents))\n",
        "    doc_num = tf_doc[index]\n",
        "    sentence = doc.split()\n",
        "    for word in sentence:\n",
        "      for text in query_tokens:\n",
        "        if(text == word):\n",
        "          idx = sentence.index(word)\n",
        "          tf_idf_score = doc_num[word] * idf_dict[word]\n",
        "          tf_idf.append(tf_idf_score)\n",
        "          df.iloc[index, df.columns.get_loc(word)] = tf_idf_score\n",
        "    index += 1\n",
        "  df.fillna(0, axis=1, inplace=True)\n",
        "  return tf_idf, df\n",
        "\n",
        "documents = [doc1, doc2, doc3]\n",
        "tf_idf, df = compute_tfidf_with_alldocs(documents, query)\n",
        "print(df)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KR8Yyskzk0s",
        "outputId": "584cf652-a766-4f3c-b183-992227deabc7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   doc      life  learning\n",
            "0    0  0.209861  0.140547\n",
            "1    1  0.000000  0.000000\n",
            "2    2  0.000000  0.468488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Space Models and Representation - Cosine Similarity"
      ],
      "metadata": {
        "id": "agdHbHvS3QLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalized TF for the query string(\"life learning\")\n",
        "\n",
        "def compute_query_tf(query):\n",
        "  query_norm_tf= {}\n",
        "  tokens = query.split()\n",
        "  for word in tokens:\n",
        "    query_norm_tf[word] = termFrequency(word, query)\n",
        "  return query_norm_tf\n",
        "query_norm_tf = compute_query_tf(query)\n",
        "print(query_norm_tf)"
      ],
      "metadata": {
        "id": "d4yL5sLH3lmQ",
        "outputId": "647cffa3-3810-4998-c5fc-5838e86f23a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'life': 0.5, 'learning': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#idf score for the query string(\"life learning\")\n",
        "def compute_query_idf(query):\n",
        "  idf_dict_qry = {}\n",
        "  sentence = query.split()\n",
        "  documents = [doc1, doc2, doc3]\n",
        "  for word in sentence:\n",
        "    idf_dict_qry[word] = inverseDocumentFrequency(word, documents)\n",
        "  return idf_dict_qry\n",
        "idf_dict_qry = compute_query_idf(query)\n",
        "print(idf_dict_qry)"
      ],
      "metadata": {
        "id": "-LqU33-F7xEG",
        "outputId": "3f167b51-1793-4d5c-d6ae-ecbf9a10d3ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'life': 2.09861228866811, 'learning': 1.4054651081081644}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upto now we have calculated tf-idf score for three documents but when we calculate cosine similarity. we have to represent our query in vector space as well. we need to calculate cosine similarity for query as well."
      ],
      "metadata": {
        "id": "_glZREFO83MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf-idf score for the query string(\"life learning\")\n",
        "def compute_query_tfidf(query):\n",
        "  tfidf_dict_qry = {}\n",
        "  sentence = query.split()\n",
        "  for word in sentence:\n",
        "    tfidf_dict_qry[word] = query_norm_tf[word]*idf_dict_qry[word]\n",
        "  return tfidf_dict_qry\n",
        "tfidf_dict_qry = compute_query_tfidf(query)\n",
        "print(tfidf_dict_qry)"
      ],
      "metadata": {
        "id": "qd0IvUvU-VB9",
        "outputId": "e64e900f-adcc-4bd6-8abf-f4d840b6524f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'life': 1.049306144334055, 'learning': 0.7027325540540822}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now Find cosine similarity between document and query"
      ],
      "metadata": {
        "id": "oZ6ERfOu_MdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(tfidf_dict_qry, df, query, doc_num):\n",
        "  dot_product = 0\n",
        "  qry_mod = 0\n",
        "  doc_mod = 0\n",
        "  tokens = query.split()\n",
        "\n",
        "  for keyword in tokens:\n",
        "    dot_product += tfidf_dict_qry[keyword]*df[keyword][df['doc']==doc_num]\n",
        "    #//Query//\n",
        "    qry_mod += tfidf_dict_qry[keyword]*tfidf_dict_qry[keyword]\n",
        "    #//Document//\n",
        "    doc_mod += df[keyword][df['doc']==doc_num]*df[keyword][df['doc']==doc_num]\n",
        "  qry_mod = np.sqrt(qry_mod)\n",
        "  doc_mod = np.sqrt(doc_mod)\n",
        "  #implement formula\n",
        "  denominator = qry_mod*doc_mod\n",
        "  cos_sin = dot_product/denominator\n",
        "\n",
        "  return cos_sin\n",
        "\n",
        "from collections import Iterable\n",
        "def flatten(lis):\n",
        "  for item in lis:\n",
        "    if isinstance(item,Iterable) and not isinstance(item, str):\n",
        "      for x in flatten(item):\n",
        "        yield x\n",
        "      else:\n",
        "        yield item\n",
        "\n"
      ],
      "metadata": {
        "id": "yDE5Brdj_UVX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_similarity_docs(data):\n",
        "  cos_sin = []\n",
        "  for doc_num in range(0,len(data)):\n",
        "    cos_sin.append(cosine_similarity(tfidf_dict_qry, df, query, doc_num).tolist())\n",
        "  return cos_sin\n",
        "similarity_docs = rank_similarity_docs(documents)\n",
        "doc_names = [\"Document1\", \"Document2\", \"Document3\"]\n",
        "print(doc_names)\n",
        "print(list(flatten(similarity_docs)))\n"
      ],
      "metadata": {
        "id": "ie67bboECcvK",
        "outputId": "077c3478-e19d-44d3-86f8-23d8c5e40312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Document1', 'Document2', 'Document3']\n",
            "[[1.0], [nan], [0.5564505207186616]]\n"
          ]
        }
      ]
    }
  ]
}