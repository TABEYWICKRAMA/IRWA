{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBzlo9uy/GfvtDBO9rrlnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TABEYWICKRAMA/IRWA/blob/main/Lab%2003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 03 IRWA"
      ],
      "metadata": {
        "id": "N2F0HAFeqaPu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfDJhf-TqTWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881cc7e9-eb4e-4ff0-c108-5051d362c73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/IRWA_LAB03"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn333qTXqoQt",
        "outputId": "2a19d6df-33d6-4ae8-8267-43986d703925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA_LAB03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize them then get that list put it to the ngram method in the nltk library\n",
        "#when we use ngram method we have to give two parameters \n",
        "#01. tokenizer \n",
        "#02. number - how many times we have to gram it\n",
        "\n",
        "#tokenizing part is happening here\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "\n",
        "text = \"April is the best month\"\n",
        "tokenize = word_tokenize(text)\n",
        "print(tokenize)\n",
        "\n",
        "#bigram part is happening here\n",
        "\n",
        "# ngrams = 2 -> bigram\n",
        "# ngrams = 3 -> trigram\n",
        "\n",
        "ng = ngrams(tokenize,2)   #if we want bigram -> 2 or trigram -> 3\n",
        "\n",
        "# for n in ng:\n",
        "#   print(n)\n",
        "\n",
        "# output          #get grams\n",
        "# ('April', 'is')\n",
        "# ('is', 'the')\n",
        "# ('the', 'best')\n",
        "# ('best', 'month')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjSFRBdBqt3t",
        "outputId": "3b23c130-f81c-455d-df92-fad1564a651d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['April', 'is', 'the', 'best', 'month']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokens are going to gram"
      ],
      "metadata": {
        "id": "FHb9Wk15rrlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display as a list\n",
        "x = [' '.join (ngramed) for ngramed in ng]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm__U_sPpdEC",
        "outputId": "678ec6a3-760d-4553-bb76-722e7e0adb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['April is', 'is the', 'the best', 'best month']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this thing get from an error\n",
        "#this runs before above 2 code runs(if it is first runs)\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw86qXOhtB6s",
        "outputId": "cb655e35-2d44-4746-fc45-47924a84c0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "text = \"April is the best month\"\n",
        "\n",
        "#get character list\n",
        "characters=[char for char in text]\n",
        "print(characters)\n",
        "\n",
        "#ngram\n",
        "ng=ngrams(characters,2)\n",
        "\n",
        "#display as a list\n",
        "x = [' '.join (ngramed) for ngramed in ng]\n",
        "print(x)"
      ],
      "metadata": {
        "id": "WmaKGNyLtHyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb84eeb1-a7e4-4659-a7c1-b1dc71a45dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'p', 'r', 'i', 'l', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'b', 'e', 's', 't', ' ', 'm', 'o', 'n', 't', 'h']\n",
            "['A p', 'p r', 'r i', 'i l', 'l  ', '  i', 'i s', 's  ', '  t', 't h', 'h e', 'e  ', '  b', 'b e', 'e s', 's t', 't  ', '  m', 'm o', 'o n', 'n t', 't h']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply K-gram for each of the directories"
      ],
      "metadata": {
        "id": "ZLjLm7sLyeA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to get the current working directory\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "directory = os.getcwd()+'' #if we have several folders inside IRWA_LAB03 then set the path to data files in here. ex: '/dataset/ngram'\n",
        "filelist=os.listdir(directory)\n",
        "print(filelist)    #this will print all the documents in set path\n",
        "\n",
        "#output\n",
        "# ['D4.txt', 'D3.txt', 'D2.txt', 'D1.txt']\n",
        "\n",
        "\n",
        "#now this will print the content in the documents\n",
        "for file in filelist:\n",
        "  with open(os.getcwd()+'/'+file,'r') as f:\n",
        "    # print(f.read()) -------------------------------------------------->>>>>>\n",
        "    sentence = f.read()       #now split them to characters                     #output\n",
        "    print(sentence)                                                             # I do not like them, Sam I am.\n",
        "    characters = [char for char in sentence]                                    # I do not like green eggs and ham.\n",
        "    print(characters)                                                           # Sam I am. \n",
        "                                                                                # I am Sam.\n",
        "                                                                                \n",
        "                                                                                \n",
        "    \n",
        "# output  -- >   split words into characters\n",
        "# I do not like them, Sam I am.\n",
        "# ['I', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'h', 'e', 'm', ',', ' ', 'S', 'a', 'm', ' ', 'I', ' ', 'a', 'm', '.']\n",
        "# I do not like green eggs and ham.\n",
        "# ['I', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 'g', 'r', 'e', 'e', 'n', ' ', 'e', 'g', 'g', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'a', 'm', '.']\n",
        "# Sam I am. \n",
        "# ['S', 'a', 'm', ' ', 'I', ' ', 'a', 'm', '.', ' ']\n",
        "# I am Sam. \n",
        "# ['I', ' ', 'a', 'm', ' ', 'S', 'a', 'm', '.', ' ']\n",
        "\n",
        "\n",
        "    #ngram\n",
        "    ng=ngrams(characters,2)      #this is for k = 2 \n",
        "\n",
        "    #display as a list\n",
        "    x = [''.join (ngramed) for ngramed in ng]\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIb_LZD7ymc6",
        "outputId": "5d470295-72cc-429f-af2e-ca47e7a60498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA_LAB03\n",
            "['D4.txt', 'D3.txt', 'D2.txt', 'D1.txt']\n",
            "I do not like them, Sam I am.\n",
            "['I', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'h', 'e', 'm', ',', ' ', 'S', 'a', 'm', ' ', 'I', ' ', 'a', 'm', '.']\n",
            "['I ', ' d', 'do', 'o ', ' n', 'no', 'ot', 't ', ' l', 'li', 'ik', 'ke', 'e ', ' t', 'th', 'he', 'em', 'm,', ', ', ' S', 'Sa', 'am', 'm ', ' I', 'I ', ' a', 'am', 'm.']\n",
            "I do not like green eggs and ham.\n",
            "['I', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 'g', 'r', 'e', 'e', 'n', ' ', 'e', 'g', 'g', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'a', 'm', '.']\n",
            "['I ', ' d', 'do', 'o ', ' n', 'no', 'ot', 't ', ' l', 'li', 'ik', 'ke', 'e ', ' g', 'gr', 're', 'ee', 'en', 'n ', ' e', 'eg', 'gg', 'gs', 's ', ' a', 'an', 'nd', 'd ', ' h', 'ha', 'am', 'm.']\n",
            "Sam I am. \n",
            "['S', 'a', 'm', ' ', 'I', ' ', 'a', 'm', '.', ' ']\n",
            "['Sa', 'am', 'm ', ' I', 'I ', ' a', 'am', 'm.', '. ']\n",
            "I am Sam. \n",
            "['I', ' ', 'a', 'm', ' ', 'S', 'a', 'm', '.', ' ']\n",
            "['I ', ' a', 'am', 'm ', ' S', 'Sa', 'am', 'm.', '. ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# covert above thing to **function**\n",
        "Answer for question 01) a)\n",
        "1). Let assume the following corpus\n",
        "D1 : I am Sam. \n",
        "D2 : Sam I am. \n",
        "D3 : I do not like green eggs and ham. \n",
        "D4 : I do not like them, Sam I am.\n",
        "a).Write the code to create k-grams for the above corpus when k=1,2,3\n"
      ],
      "metadata": {
        "id": "mcvptjtI9KQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to get the current working directory\n",
        "import os\n",
        "\n",
        "#print(os.getcwd())\n",
        "def get_ngram(n):                     ###################    modify     ########################\n",
        "  directory = os.getcwd()+'' #if we have several folders inside IRWA_LAB03 then set the path to data files in here. ex: '/dataset/ngram'\n",
        "  filelist=os.listdir(directory)\n",
        "  print(filelist)    #this will print all the documents in set path\n",
        "\n",
        "  #output\n",
        "  # ['D4.txt', 'D3.txt', 'D2.txt', 'D1.txt']\n",
        "\n",
        "\n",
        "  #now this will print the content in the documents\n",
        "  for file in filelist:\n",
        "    with open(os.getcwd()+'/'+file,'r') as f:\n",
        "      # print(f.read()) \n",
        "      sentence = f.read()       #now split them to characters                     \n",
        "      print(sentence)                                                             \n",
        "      characters = [char for char in sentence]                                    \n",
        "      print(characters)                                                          \n",
        "                                                                                  \n",
        "      #ngram\n",
        "      ng=ngrams(characters,n)      #this is for k = 2 ###################    modify     ########################\n",
        "\n",
        "      #display as a list\n",
        "      x = [''.join (ngramed) for ngramed in ng]\n",
        "      print(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "e9tSBNvV9OsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ngram(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htPB8I_594hz",
        "outputId": "06faebc5-f400-4588-95f6-3782147fb1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['D4.txt', 'D3.txt', 'D2.txt', 'D1.txt']\n",
            "I do not like them, Sam I am.\n",
            "['I', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'h', 'e', 'm', ',', ' ', 'S', 'a', 'm', ' ', 'I', ' ', 'a', 'm', '.']\n",
            "['I ', ' d', 'do', 'o ', ' n', 'no', 'ot', 't ', ' l', 'li', 'ik', 'ke', 'e ', ' t', 'th', 'he', 'em', 'm,', ', ', ' S', 'Sa', 'am', 'm ', ' I', 'I ', ' a', 'am', 'm.']\n",
            "I do not like green eggs and ham.\n",
            "['I', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 'g', 'r', 'e', 'e', 'n', ' ', 'e', 'g', 'g', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'a', 'm', '.']\n",
            "['I ', ' d', 'do', 'o ', ' n', 'no', 'ot', 't ', ' l', 'li', 'ik', 'ke', 'e ', ' g', 'gr', 're', 'ee', 'en', 'n ', ' e', 'eg', 'gg', 'gs', 's ', ' a', 'an', 'nd', 'd ', ' h', 'ha', 'am', 'm.']\n",
            "Sam I am. \n",
            "['S', 'a', 'm', ' ', 'I', ' ', 'a', 'm', '.', ' ']\n",
            "['Sa', 'am', 'm ', ' I', 'I ', ' a', 'am', 'm.', '. ']\n",
            "I am Sam. \n",
            "['I', ' ', 'a', 'm', ' ', 'S', 'a', 'm', '.', ' ']\n",
            "['I ', ' a', 'am', 'm ', ' S', 'Sa', 'am', 'm.', '. ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b).Write code to find out the Jaccard coefficient between the given documents based on \n",
        "different k.\n"
      ],
      "metadata": {
        "id": "_X-wurK8-ePa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jc = X intersection Y / X union Y  \n",
        "\n",
        "def jaccard(x,y):\n",
        "  numerator = x.intersection(y)\n",
        "  denomenator = x.union(y)\n",
        "  return len(numerator)/len(denomenator)    #we use len function because characters can not divide\n",
        "\n",
        "\n",
        "D3=open(os.getcwd()+'/D3.txt','r')\n",
        "# print(D3)  #this will give an object\n",
        "# print(D3.read())  #this will show content\n",
        "\n",
        "sentence = D3.read()\n",
        "print(sentence)\n",
        "\n",
        "#split into character set\n",
        "sentence = [char for char in sentence]                                    \n",
        "#print(sentence)                                                          \n",
        "#ngram\n",
        "ng=ngrams(sentence,2)      #this is for k = 2 ###################    modify     ########################\n",
        "\n",
        "#display as a list\n",
        "x = [''.join (ngramed) for ngramed in ng]\n",
        "print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "D4=open(os.getcwd()+'/D4.txt','r')\n",
        "# print(D4)  #this will give an object\n",
        "# print(D4.read())  #this will show content\n",
        "\n",
        "sentence = D4.read()\n",
        "print(sentence)\n",
        "\n",
        "#split into character set\n",
        "sentence = [char for char in sentence]                                    \n",
        "#print(sentence)                                                          \n",
        "#ngram\n",
        "ng=ngrams(sentence,2)      #this is for k = 2 ###################    modify     ########################\n",
        "\n",
        "#display as a list\n",
        "y = [''.join (ngramed) for ngramed in ng]\n",
        "print(y)\n",
        "\n",
        "\n",
        "jaccard(set(x),set(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az5SJ3XU-Oe6",
        "outputId": "98029717-095d-45b3-f6fa-83bed9cc8fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not like green eggs and ham.\n",
            "['I ', ' d', 'do', 'o ', ' n', 'no', 'ot', 't ', ' l', 'li', 'ik', 'ke', 'e ', ' g', 'gr', 're', 'ee', 'en', 'n ', ' e', 'eg', 'gg', 'gs', 's ', ' a', 'an', 'nd', 'd ', ' h', 'ha', 'am', 'm.']\n",
            "I do not like them, Sam I am.\n",
            "['I ', ' d', 'do', 'o ', ' n', 'no', 'ot', 't ', ' l', 'li', 'ik', 'ke', 'e ', ' t', 'th', 'he', 'em', 'm,', ', ', ' S', 'Sa', 'am', 'm ', ' I', 'I ', ' a', 'am', 'm.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38095238095238093"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Apply levenshtein algorithm to “python” and “pythonly” and **get the minimum edit distance**"
      ],
      "metadata": {
        "id": "OaPPEPqyJ5hC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using nltk"
      ],
      "metadata": {
        "id": "e4Q-kdebNCEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.metrics.distance import edit_distance\n",
        "print(edit_distance(\"python\",\"pythonly\"))\n",
        "\n",
        "# change python to pythonly --> only change 2 characters"
      ],
      "metadata": {
        "id": "pTghCHjSeKBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02e5185-b07c-467a-a7a7-c0a4468013dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using python levenshtein library"
      ],
      "metadata": {
        "id": "70jM8B1SNG9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1PU3gooL3js",
        "outputId": "d8447dd9-8314-4e3b-f81b-fe54b25e18f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149876 sha256=02768bb75163059daf14b0f1c27a826b90f1772c9e0f5c79422148cf286aac7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein as lv\n",
        "print(lv.distance(\"python\",\"pythonly\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9h2SD0XNLyS",
        "outputId": "1aad9658-939b-4080-f6c9-80232d474339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Implement the SOUNDEX algorithm"
      ],
      "metadata": {
        "id": "4N4Q4rm5N1nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#same pranouncation give same value\n",
        "# ex: Hermann & Herman will give same output\n",
        "name=\"Hermann\"\n",
        "name=name.upper()\n",
        "soundex=\"\"\n",
        "#1st Rule\n",
        "soundex+=name[0]\n",
        "#2nd and 3rd rule\n",
        "dictionary = {\"BFPV\":\"1\",\"CGJKQSXZ\":\"2\",\"DT\":\"3\",\"L\":\"4\",\"MN\":\"5\",\"R\":\"6\",\"AEIOUHWY\":\"0\"}\n",
        "for char in name[1:]:\n",
        "  for key in dictionary.keys():\n",
        "    if char in key:\n",
        "      code=dictionary[key]\n",
        "      # 4th Rule\n",
        "      if code != soundex[-1]:\n",
        "        soundex += code\n",
        "        #5th Rule\n",
        "        soundex = soundex.replace(\"0\",\"\")\n",
        "        #6th Rule\n",
        "        soundex = soundex[:4].ljust(4,\"0\")\n",
        "print(soundex)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAqb2wkfN36i",
        "outputId": "3ae52545-d8c5-4ea6-c5ad-0b4a94e9cdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert above soundex section to function"
      ],
      "metadata": {
        "id": "pdnd2BYaJ0BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#same pranouncation give same value\n",
        "# name=\"Hermann\"\n",
        "def soundex(name):\n",
        "  name=name.upper()\n",
        "  soundex=\"\"\n",
        "  #1st Rule\n",
        "  soundex+=name[0]\n",
        "  #2nd and 3rd rule\n",
        "  dictionary = {\"BFPV\":\"1\",\"CGJKQSXZ\":\"2\",\"DT\":\"3\",\"L\":\"4\",\"MN\":\"5\",\"R\":\"6\",\"AEIOUHWY\":\"0\"}\n",
        "  for char in name[1:]:\n",
        "    for key in dictionary.keys():\n",
        "      if char in key:\n",
        "        code=dictionary[key]\n",
        "        # 4th Rule\n",
        "        if code != soundex[-1]:\n",
        "          soundex += code\n",
        "          #5th Rule\n",
        "          soundex = soundex.replace(\"0\",\"\")\n",
        "          #6th Rule\n",
        "          soundex = soundex[:4].ljust(4,\"0\")\n",
        "  return(soundex)\n"
      ],
      "metadata": {
        "id": "3ibQne67vTdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soundex(\"Herman\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ya0ZOnwAvbac",
        "outputId": "b4d183cc-9cfd-4370-c7c6-188212269d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'H655'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soundex(\"Hermann\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e0FRRqNsKYDA",
        "outputId": "fc7a6a03-2441-4dc9-cf49-aae597df4ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'H655'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "profimity operator is for clouseness"
      ],
      "metadata": {
        "id": "mC5PPsGzQppi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#profimity operators can not just apply\n",
        "#if they mention in the question then we can apply\n",
        "#there are two operators\n",
        "# 01.near operator - n\n",
        "# 02.within operator w\n",
        "\n",
        "#near operator nX\n",
        "# television n2 violence   ---->  television or violence may come first. it doesn't matter. but these two words are near each other. ex : television clouds violence,  violence film television \n",
        "\n",
        "\n",
        "\n",
        "#within operator wX\n",
        "# television w2 violence    ----->   television should come first. within two words violence should be there.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MCVhEulFLQPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}